{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A template Jupyter notebook to further train models.\n",
    "Data is given in compressed form and extracted for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "norm_method = 'std'  # data normalization\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "balance_classes = True  # sample each class equally\n",
    "max_class_samples = 1e6  # max number of samples per class\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'watershed'\n",
    "distance_bins = 4  # number of distance \"classes\"\n",
    "erosion_width = 1  # erode edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"20190621_postprocessing\"\n",
    "MODEL_DIR = os.path.join(\"/data/models\", experiment_folder)\n",
    "LOG_DIR = '/data/logs'\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Point1_12_18_20190606_output_3_class_w_interior_and_watershed'\n",
    "npz_name = '/data/npz_data/' + base_name + \".npz\"\n",
    "\n",
    "sample_model_name = base_name + \"_watershed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 1024, 1024, 4) & y.shape: (3, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "CHANNEL_AXIS = 3\n",
    "training_data = np.load(npz_name)\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "from deepcell.training import train_model_sample\n",
    "\n",
    "watershed_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=distance_bins,\n",
    "    n_conv_filters=64,\n",
    "    n_dense_filters=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point1_12_18_20190606_output_3_class_w_interior_and_watershed_watershed\n"
     ]
    }
   ],
   "source": [
    "print(sample_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "X_train shape: (3, 1024, 1024, 4)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 60000\n",
      "analyzing image 0\n",
      "the least represented class has 30524 examples\n",
      "analyzing class 0\n",
      "downsampling from 739622 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 95868 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 61355 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 30524 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 37791 examples\n",
      "analyzing class 0\n",
      "downsampling from 687593 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 121406 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 80579 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 37791 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 44239 examples\n",
      "analyzing class 0\n",
      "downsampling from 646714 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 141277 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 95139 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 44239 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/40\n",
      "7034/7034 [==============================] - 745s 106ms/step - loss: 0.6650 - acc: 0.6830\n",
      "Epoch 2/40\n",
      "7034/7034 [==============================] - 727s 103ms/step - loss: 0.6312 - acc: 0.7000\n",
      "Epoch 3/40\n",
      "7034/7034 [==============================] - 722s 103ms/step - loss: 0.6201 - acc: 0.7053\n",
      "Epoch 4/40\n",
      "7034/7034 [==============================] - 715s 102ms/step - loss: 0.6104 - acc: 0.7097\n",
      "Epoch 5/40\n",
      "6762/7034 [===========================>..] - ETA: 27s - loss: 0.6023 - acc: 0.7135"
     ]
    }
   ],
   "source": [
    "watershed_model = train_model_sample(\n",
    "    model=watershed_model,\n",
    "    dataset=npz_name, \n",
    "    model_name=sample_model_name,\n",
    "    test_size=0.1,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=40,\n",
    "    window_size=(win, win),\n",
    "    transform=transform,\n",
    "    distance_bins=distance_bins,\n",
    "    erosion_width=erosion_width,\n",
    "    balance_classes=True,\n",
    "    max_class_samples=180000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
