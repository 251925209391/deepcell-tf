{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed Distance Transform for 2D Data\n",
    "---\n",
    "Implementation of papers:\n",
    "\n",
    "[Deep Watershed Transform for Instance Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Bai_Deep_Watershed_Transform_CVPR_2017_paper.pdf)\n",
    "\n",
    "[Learn to segment single cells with deep distance estimator and deep cell detector](https://arxiv.org/abs/1803.10829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/deepcell/utils/__init__.py:49: UserWarning: To use `compute_overlap`, the C extensions must be built using `python setup.py build_ext --inplace`\n",
      "  warnings.warn('To use `compute_overlap`, the C extensions must be built '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "import deepcell\n",
    "from tensorflow.python import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "test_size = .10  # % of data saved as test\n",
    "norm_method = 'std'  # data normalization\n",
    "receptive_field = 81  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "balance_classes = True  # sample each class equally\n",
    "max_class_samples = 1e6  # max number of samples per class\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'watershed'\n",
    "distance_bins = 4  # number of distance \"classes\"\n",
    "erosion_width = 3  # erode edges\n",
    "LOG_DIR = '/data/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Training_Freeze_1_Nuc'\n",
    "npz_name = '/data/npz_data/' + base_name + \".npz\"\n",
    "MODEL_DIR = '/data/models/' + '20190822_training_freeze_1'\n",
    "sample_model_name = base_name + \"_watershed_81_rf_256_dense_64_conv_3erosion\"\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (4, 1024, 1024, 5) & y.shape: (4, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "CHANNEL_AXIS = 3\n",
    "training_data = np.load(npz_name)\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model for the watershed energy transform\n",
    "\n",
    "#### Instantiate the distance transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "from deepcell.training import train_model_sample\n",
    "\n",
    "watershed_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=distance_bins,\n",
    "    n_conv_filters=64,\n",
    "    n_dense_filters=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training_Freeze_1_Nuc_watershed_81_rf_256_dense_64_conv_3erosion'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_model.load_weights(\"/data/models/20190822_training_freeze_1/Training_Freeze_1_Nuc_watershed_81_rf_256_dense_64_conv_2erosion_epoch_12.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "X_train shape: (4, 1024, 1024, 5)\n",
      "y_train shape: (4, 1024, 1024, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 60000\n",
      "analyzing image 0\n",
      "the least represented class has 34576 examples\n",
      "analyzing class 0\n",
      "downsampling from 664627 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 114784 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 75262 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 34576 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 32630 examples\n",
      "analyzing class 0\n",
      "downsampling from 683976 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 103169 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 69474 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 32630 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 26537 examples\n",
      "analyzing class 0\n",
      "downsampling from 718049 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 86874 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 57789 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 26537 examples per class\n",
      "analyzing image 3\n",
      "the least represented class has 31272 examples\n",
      "analyzing class 0\n",
      "downsampling from 692058 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 100211 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 65708 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 31272 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/6\n",
      " 393/7813 [>.............................] - ETA: 33:38 - loss: 0.9360 - acc: 0.5433"
     ]
    }
   ],
   "source": [
    "watershed_model = train_model_sample(\n",
    "    model=watershed_model,\n",
    "    dataset=npz_name, \n",
    "    model_name=sample_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=6,\n",
    "    window_size=(win, win),\n",
    "    transform=transform,\n",
    "    distance_bins=distance_bins,\n",
    "    erosion_width=erosion_width,\n",
    "    balance_classes=True,\n",
    "    max_class_samples=240000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
