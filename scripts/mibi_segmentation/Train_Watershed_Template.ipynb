{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed Distance Transform for 2D Data\n",
    "---\n",
    "Implementation of papers:\n",
    "\n",
    "[Deep Watershed Transform for Instance Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Bai_Deep_Watershed_Transform_CVPR_2017_paper.pdf)\n",
    "\n",
    "[Learn to segment single cells with deep distance estimator and deep cell detector](https://arxiv.org/abs/1803.10829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell\n",
    "from tensorflow.python import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "n_epoch = 60  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "norm_method = 'std'  # data normalization\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "balance_classes = True  # sample each class equally\n",
    "max_class_samples = 1e6  # max number of samples per class\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'watershed'\n",
    "distance_bins = 4  # number of distance \"classes\"\n",
    "erosion_width = 1  # erode edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Point1_12_18_3X_interior_border_border'\n",
    "npz_name = '/data/npz_data/' + base_name + \".npz\"\n",
    "MODEL_DIR = '/data/models/' + '20190606_params'\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "LOG_DIR = '/data/logs'\n",
    "\n",
    "\n",
    "fgbg_model_name = base_name + \"_fgbg\"\n",
    "sample_model_name = base_name + \"_watershed_64_filters_400_densefilters_balanced\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 1024, 1024, 3) & y.shape: (3, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "CHANNEL_AXIS = 3\n",
    "training_data = np.load(npz_name)\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))\n",
    "#X = X[:, :, :, 0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, create a foreground/background separation model\n",
    "\n",
    "#### Instantiate the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "fgbg_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0}\n",
      "X_train shape: (3, 1024, 1024, 1)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 2)\n",
      "Number of Classes: 2\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 333333\n",
      "analyzing image 0\n",
      "the least represented class has 331425 examples\n",
      "analyzing class 0\n",
      "downsampling from 595944 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 331425 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 421168 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 506201 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 421168 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 434941 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 434941 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 492428 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/5\n",
      "15594/15595 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9168\n",
      "Epoch 00001: saving model to /data/models/20190525_class_balance/Point1_12_18_3X_interior_fgbg_epoch_01.h5\n",
      "15595/15595 [==============================] - 1448s 93ms/step - loss: 0.1966 - acc: 0.9168\n",
      "Epoch 2/5\n",
      "15594/15595 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9190\n",
      "Epoch 00002: saving model to /data/models/20190525_class_balance/Point1_12_18_3X_interior_fgbg_epoch_02.h5\n",
      "15595/15595 [==============================] - 1441s 92ms/step - loss: 0.1911 - acc: 0.9190\n",
      "Epoch 3/5\n",
      "15594/15595 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9199\n",
      "Epoch 00003: saving model to /data/models/20190525_class_balance/Point1_12_18_3X_interior_fgbg_epoch_03.h5\n",
      "15595/15595 [==============================] - 1440s 92ms/step - loss: 0.1886 - acc: 0.9199\n",
      "Epoch 4/5\n",
      "15594/15595 [============================>.] - ETA: 0s - loss: 0.1861 - acc: 0.9208\n",
      "Epoch 00004: saving model to /data/models/20190525_class_balance/Point1_12_18_3X_interior_fgbg_epoch_04.h5\n",
      "15595/15595 [==============================] - 1402s 90ms/step - loss: 0.1861 - acc: 0.9208\n",
      "Epoch 5/5\n",
      "15594/15595 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9217\n",
      "Epoch 00005: saving model to /data/models/20190525_class_balance/Point1_12_18_3X_interior_fgbg_epoch_05.h5\n",
      "15595/15595 [==============================] - 1419s 91ms/step - loss: 0.1843 - acc: 0.9217\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_sample\n",
    "\n",
    "fgbg_model = train_model_sample(\n",
    "    model=fgbg_model,\n",
    "    dataset=npz_name,\n",
    "    model_name=fgbg_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    window_size=(win, win),\n",
    "    batch_size=128,\n",
    "    transform='fgbg',\n",
    "    n_epoch=5,\n",
    "    balance_classes=balance_classes,\n",
    "    max_class_samples=1000000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, Create a model for the watershed energy transform\n",
    "\n",
    "#### Instantiate the distance transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "from deepcell.training import train_model_sample\n",
    "\n",
    "watershed_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=distance_bins,\n",
    "    n_conv_filters=64,\n",
    "    n_dense_filters=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Point1_12_18_3X_interior_border_border_watershed_64_filters_400_densefilters_balanced'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_name\n",
    "#watershed_model.load_weights('/data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_128_filters_balanced_epoch_40.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "X_train shape: (3, 1024, 1024, 3)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 60000\n",
      "analyzing image 0\n",
      "the least represented class has 30524 examples\n",
      "analyzing class 0\n",
      "downsampling from 739622 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 95868 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 61355 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 30524 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 37791 examples\n",
      "analyzing class 0\n",
      "downsampling from 687593 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 121406 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 80579 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 37791 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 44239 examples\n",
      "analyzing class 0\n",
      "downsampling from 646714 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 141277 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 95139 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 44239 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/60\n",
      "7034/7034 [==============================] - 537s 76ms/step - loss: 0.7616 - acc: 0.6331\n",
      "Epoch 2/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.7202 - acc: 0.6528\n",
      "Epoch 3/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.7077 - acc: 0.6583\n",
      "Epoch 4/60\n",
      "7034/7034 [==============================] - 531s 76ms/step - loss: 0.6991 - acc: 0.6639\n",
      "Epoch 5/60\n",
      "7034/7034 [==============================] - 531s 75ms/step - loss: 0.6938 - acc: 0.6674\n",
      "Epoch 6/60\n",
      "7034/7034 [==============================] - 538s 77ms/step - loss: 0.6874 - acc: 0.6683\n",
      "Epoch 7/60\n",
      "7034/7034 [==============================] - 536s 76ms/step - loss: 0.6831 - acc: 0.6720\n",
      "Epoch 8/60\n",
      "7034/7034 [==============================] - 549s 78ms/step - loss: 0.6782 - acc: 0.6745\n",
      "Epoch 9/60\n",
      "7034/7034 [==============================] - 539s 77ms/step - loss: 0.6746 - acc: 0.6756\n",
      "Epoch 10/60\n",
      "7033/7034 [============================>.] - ETA: 0s - loss: 0.6710 - acc: 0.6778\n",
      "Epoch 00010: saving model to /data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_64_filters_400_densefilters_balanced_epoch_10.h5\n",
      "7034/7034 [==============================] - 540s 77ms/step - loss: 0.6710 - acc: 0.6779\n",
      "Epoch 11/60\n",
      "7034/7034 [==============================] - 541s 77ms/step - loss: 0.6664 - acc: 0.6804\n",
      "Epoch 12/60\n",
      "7034/7034 [==============================] - 535s 76ms/step - loss: 0.6635 - acc: 0.6824\n",
      "Epoch 13/60\n",
      "7034/7034 [==============================] - 534s 76ms/step - loss: 0.6578 - acc: 0.6856\n",
      "Epoch 14/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.6530 - acc: 0.6878\n",
      "Epoch 15/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.6388 - acc: 0.6969\n",
      "Epoch 16/60\n",
      "7034/7034 [==============================] - 552s 78ms/step - loss: 0.6149 - acc: 0.7112\n",
      "Epoch 17/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5991 - acc: 0.7208\n",
      "Epoch 18/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5876 - acc: 0.7270\n",
      "Epoch 19/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5796 - acc: 0.7320\n",
      "Epoch 20/60\n",
      "7033/7034 [============================>.] - ETA: 0s - loss: 0.5725 - acc: 0.7347\n",
      "Epoch 00020: saving model to /data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_64_filters_400_densefilters_balanced_epoch_20.h5\n",
      "7034/7034 [==============================] - 534s 76ms/step - loss: 0.5725 - acc: 0.7347\n",
      "Epoch 21/60\n",
      "7034/7034 [==============================] - 538s 76ms/step - loss: 0.5664 - acc: 0.7388\n",
      "Epoch 22/60\n",
      "7034/7034 [==============================] - 535s 76ms/step - loss: 0.5608 - acc: 0.7412\n",
      "Epoch 23/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5565 - acc: 0.7434\n",
      "Epoch 24/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5517 - acc: 0.7454\n",
      "Epoch 25/60\n",
      " 270/7034 [>.............................] - ETA: 8:32 - loss: 0.5411 - acc: 0.7560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7034/7034 [==============================] - 540s 77ms/step - loss: 0.5484 - acc: 0.7481\n",
      "Epoch 26/60\n",
      "7034/7034 [==============================] - 537s 76ms/step - loss: 0.5449 - acc: 0.7502\n",
      "Epoch 27/60\n",
      "7034/7034 [==============================] - 543s 77ms/step - loss: 0.5414 - acc: 0.7514\n",
      "Epoch 28/60\n",
      "7034/7034 [==============================] - 541s 77ms/step - loss: 0.5385 - acc: 0.7529\n",
      "Epoch 29/60\n",
      "7034/7034 [==============================] - 540s 77ms/step - loss: 0.5364 - acc: 0.7546\n",
      "Epoch 30/60\n",
      "7033/7034 [============================>.] - ETA: 0s - loss: 0.5331 - acc: 0.7560\n",
      "Epoch 00030: saving model to /data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_64_filters_400_densefilters_balanced_epoch_30.h5\n",
      "7034/7034 [==============================] - 539s 77ms/step - loss: 0.5330 - acc: 0.7560\n",
      "Epoch 31/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5305 - acc: 0.7572\n",
      "Epoch 32/60\n",
      "7034/7034 [==============================] - 534s 76ms/step - loss: 0.5275 - acc: 0.7592\n",
      "Epoch 33/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5246 - acc: 0.7604\n",
      "Epoch 34/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5237 - acc: 0.7614\n",
      "Epoch 35/60\n",
      "7034/7034 [==============================] - 540s 77ms/step - loss: 0.5208 - acc: 0.7621\n",
      "Epoch 36/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5194 - acc: 0.7630\n",
      "Epoch 37/60\n",
      "7034/7034 [==============================] - 538s 77ms/step - loss: 0.5168 - acc: 0.7644\n",
      "Epoch 38/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5152 - acc: 0.7655\n",
      "Epoch 39/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5130 - acc: 0.7670\n",
      "Epoch 40/60\n",
      "7033/7034 [============================>.] - ETA: 0s - loss: 0.5119 - acc: 0.7670\n",
      "Epoch 00040: saving model to /data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_64_filters_400_densefilters_balanced_epoch_40.h5\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5119 - acc: 0.7670\n",
      "Epoch 41/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5096 - acc: 0.7680\n",
      "Epoch 42/60\n",
      "7034/7034 [==============================] - 536s 76ms/step - loss: 0.5070 - acc: 0.7696\n",
      "Epoch 43/60\n",
      "7034/7034 [==============================] - 537s 76ms/step - loss: 0.5080 - acc: 0.7701\n",
      "Epoch 44/60\n",
      "7034/7034 [==============================] - 533s 76ms/step - loss: 0.5047 - acc: 0.7702\n",
      "Epoch 45/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5030 - acc: 0.7715\n",
      "Epoch 46/60\n",
      "7034/7034 [==============================] - 532s 76ms/step - loss: 0.5014 - acc: 0.7728\n",
      "Epoch 47/60\n",
      "7034/7034 [==============================] - 543s 77ms/step - loss: 0.4993 - acc: 0.7733\n",
      "Epoch 48/60\n",
      "7034/7034 [==============================] - 542s 77ms/step - loss: 0.4997 - acc: 0.7726\n",
      "Epoch 49/60\n",
      "7034/7034 [==============================] - 556s 79ms/step - loss: 0.4963 - acc: 0.7744\n",
      "Epoch 50/60\n",
      "7033/7034 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.7749\n",
      "Epoch 00050: saving model to /data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_64_filters_400_densefilters_balanced_epoch_50.h5\n",
      "7034/7034 [==============================] - 548s 78ms/step - loss: 0.4958 - acc: 0.7749\n",
      "Epoch 51/60\n",
      "7034/7034 [==============================] - 540s 77ms/step - loss: 0.4942 - acc: 0.7756\n",
      "Epoch 52/60\n",
      "7034/7034 [==============================] - 539s 77ms/step - loss: 0.4936 - acc: 0.7763\n",
      "Epoch 53/60\n",
      "7034/7034 [==============================] - 549s 78ms/step - loss: 0.4918 - acc: 0.7775\n",
      "Epoch 54/60\n",
      "7034/7034 [==============================] - 538s 76ms/step - loss: 0.4907 - acc: 0.7780\n",
      "Epoch 55/60\n",
      "7034/7034 [==============================] - 536s 76ms/step - loss: 0.4905 - acc: 0.7781\n",
      "Epoch 56/60\n",
      "4989/7034 [====================>.........] - ETA: 2:35 - loss: 0.4896 - acc: 0.7781"
     ]
    }
   ],
   "source": [
    "watershed_model = train_model_sample(\n",
    "    model=watershed_model,\n",
    "    dataset=npz_name, \n",
    "    model_name=sample_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=60,\n",
    "    window_size=(win, win),\n",
    "    transform=transform,\n",
    "    distance_bins=distance_bins,\n",
    "    erosion_width=erosion_width,\n",
    "    balance_classes=True,\n",
    "    max_class_samples=180000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
