{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed Distance Transform for 2D Data\n",
    "---\n",
    "Implementation of papers:\n",
    "\n",
    "[Deep Watershed Transform for Instance Segmentation](http://openaccess.thecvf.com/content_cvpr_2017/papers/Bai_Deep_Watershed_Transform_CVPR_2017_paper.pdf)\n",
    "\n",
    "[Learn to segment single cells with deep distance estimator and deep cell detector](https://arxiv.org/abs/1803.10829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/deepcell/utils/__init__.py:49: UserWarning: To use `compute_overlap`, the C extensions must be built using `python setup.py build_ext --inplace`\n",
      "  warnings.warn('To use `compute_overlap`, the C extensions must be built '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "import deepcell\n",
    "from tensorflow.python import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "test_size = .10  # % of data saved as test\n",
    "norm_method = 'std'  # data normalization\n",
    "receptive_field = 81  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "balance_classes = True  # sample each class equally\n",
    "max_class_samples = 1e6  # max number of samples per class\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'watershed'\n",
    "distance_bins = 4  # number of distance \"classes\"\n",
    "erosion_width = 2  # erode edges\n",
    "LOG_DIR = '/data/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Training_Freeze_1_Nuc_HH3'\n",
    "npz_name = '/data/npz_data/' + base_name + \".npz\"\n",
    "MODEL_DIR = '/data/models/' + '20190914_tuning'\n",
    "sample_model_name = base_name + \"_watershed_81_rf_256_dense_64_conv_2erosion\"\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (4, 1024, 1024, 1) & y.shape: (4, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "CHANNEL_AXIS = 3\n",
    "training_data = np.load(npz_name)\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model for the watershed energy transform\n",
    "\n",
    "#### Instantiate the distance transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "from deepcell.training import train_model_sample\n",
    "\n",
    "watershed_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=distance_bins,\n",
    "    n_conv_filters=64,\n",
    "    n_dense_filters=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_model.load_weights(\"/data/models/20190822_training_freeze_1/Training_Freeze_1_Nuc_watershed_81_rf_256_dense_64_conv_2erosion_epoch_12.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "X_train shape: (4, 1024, 1024, 1)\n",
      "y_train shape: (4, 1024, 1024, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 80000\n",
      "analyzing image 0\n",
      "the least represented class has 41073 examples\n",
      "analyzing class 0\n",
      "downsampling from 624037 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 135505 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 88634 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 41073 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 36892 examples\n",
      "analyzing class 0\n",
      "downsampling from 656297 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 116908 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 79152 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 36892 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 30629 examples\n",
      "analyzing class 0\n",
      "downsampling from 692322 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 99539 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 66759 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 30629 examples per class\n",
      "analyzing image 3\n",
      "the least represented class has 37710 examples\n",
      "analyzing class 0\n",
      "downsampling from 651105 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 120943 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 79491 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 37710 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/10\n",
      "9142/9144 [============================>.] - ETA: 0s - loss: 0.7913 - acc: 0.6211\n",
      "Epoch 00001: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_01.h5\n",
      "9144/9144 [==============================] - 463s 51ms/step - loss: 0.7913 - acc: 0.6211\n",
      "Epoch 2/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7512 - acc: 0.6423\n",
      "Epoch 00002: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_02.h5\n",
      "9144/9144 [==============================] - 460s 50ms/step - loss: 0.7512 - acc: 0.6423\n",
      "Epoch 3/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7380 - acc: 0.6492\n",
      "Epoch 00003: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_03.h5\n",
      "9144/9144 [==============================] - 457s 50ms/step - loss: 0.7380 - acc: 0.6492\n",
      "Epoch 4/10\n",
      "9142/9144 [============================>.] - ETA: 0s - loss: 0.7302 - acc: 0.6528\n",
      "Epoch 00004: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_04.h5\n",
      "9144/9144 [==============================] - 457s 50ms/step - loss: 0.7302 - acc: 0.6528\n",
      "Epoch 5/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7239 - acc: 0.6563\n",
      "Epoch 00005: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_05.h5\n",
      "9144/9144 [==============================] - 456s 50ms/step - loss: 0.7239 - acc: 0.6563\n",
      "Epoch 6/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7173 - acc: 0.6601\n",
      "Epoch 00006: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_06.h5\n",
      "9144/9144 [==============================] - 456s 50ms/step - loss: 0.7173 - acc: 0.6601\n",
      "Epoch 7/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7135 - acc: 0.6615\n",
      "Epoch 00007: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_07.h5\n",
      "9144/9144 [==============================] - 457s 50ms/step - loss: 0.7135 - acc: 0.6615\n",
      "Epoch 8/10\n",
      "9142/9144 [============================>.] - ETA: 0s - loss: 0.7092 - acc: 0.6646\n",
      "Epoch 00008: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_08.h5\n",
      "9144/9144 [==============================] - 456s 50ms/step - loss: 0.7092 - acc: 0.6646\n",
      "Epoch 9/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7039 - acc: 0.6661\n",
      "Epoch 00009: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_09.h5\n",
      "9144/9144 [==============================] - 456s 50ms/step - loss: 0.7040 - acc: 0.6661\n",
      "Epoch 10/10\n",
      "9143/9144 [============================>.] - ETA: 0s - loss: 0.7001 - acc: 0.6673\n",
      "Epoch 00010: saving model to /data/models/20190914_tuning/Training_Freeze_1_Nuc_HH3_watershed_81_rf_256_dense_64_conv_2erosion_epoch_10.h5\n",
      "9144/9144 [==============================] - 456s 50ms/step - loss: 0.7001 - acc: 0.6673\n"
     ]
    }
   ],
   "source": [
    "watershed_model = train_model_sample(\n",
    "    model=watershed_model,\n",
    "    dataset=npz_name, \n",
    "    model_name=sample_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=10,\n",
    "    window_size=(win, win),\n",
    "    transform=transform,\n",
    "    distance_bins=distance_bins,\n",
    "    erosion_width=erosion_width,\n",
    "    balance_classes=True,\n",
    "    max_class_samples=320000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
