{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A template Jupyter notebook to further train models.\n",
    "Data is given in compressed form and extracted for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.python import keras\n",
    "\n",
    "from deepcell.utils.data_utils import make_training_data\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.io_utils import get_image_sizes\n",
    "from deepcell.utils.export_utils import export_model\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.model_zoo import bn_feature_net_2D\n",
    "from deepcell.model_zoo import bn_feature_net_skip_2D\n",
    "#from deepcell.training import train_model_sample\n",
    "import deepcell.training\n",
    "import deepcell.image_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'deepcell.image_generators' from '/usr/local/lib/python3.5/dist-packages/deepcell/image_generators.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(deepcell.training)\n",
    "importlib.reload(deepcell.image_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = False\n",
    "RESHAPE_SIZE = 256\n",
    "\n",
    "# filepath constants\n",
    "ROOT_DIR = \"/data/output\"\n",
    "DATA_DIR = \"/data/contour_data/\"\n",
    "MODEL_DIR = \"/data/models\"\n",
    "NPZ_DIR = \"/data/npz_data\"\n",
    "LOG_DIR = \"/data/logs\"\n",
    "DATA_FILE = \"Point1_12_18_3X\"\n",
    "RAW_PATH = os.path.join(DATA_DIR, DATA_FILE)\n",
    "\n",
    "# Check for channels_first or channels_last\n",
    "IS_CHANNELS_FIRST = keras.backend.image_data_format() == \"channels_first\"\n",
    "ROW_AXIS = 2 if IS_CHANNELS_FIRST else 1\n",
    "COL_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else 3\n",
    "\n",
    "N_FRAMES = 5\n",
    "\n",
    "# for d in (NPZ_DIR, MODEL_DIR, LOG_DIR, DATA_DIR):\n",
    "#     if not d.startswith(\"/\"):\n",
    "#         continue  # not a local directory, no need to create it\n",
    "#     try:\n",
    "#         os.makedirs(d)\n",
    "#     except OSError as exc:\n",
    "#         if exc.errno != errno.EEXIST:\n",
    "#             raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_training_data(\n",
    "#     channel_names=['Nuclear_Interior.tif'],\n",
    "#     file_name_save=os.path.join(NPZ_DIR, \"Point1_12_18_3X_interior\"),\n",
    "#     dimensionality=2,\n",
    "#     annotation_direc=\"annotated\",\n",
    "#     annotation_name='Nuclear_Interior_Border_Mask_Label',\n",
    "#     reshape_size=RESHAPE_SIZE if RESIZE else None,\n",
    "#     training_direcs=None,\n",
    "#     raw_image_direc=\"raw\",\n",
    "#     direc_name=os.path.join(DATA_DIR, DATA_FILE)\n",
    "# )\n",
    "\n",
    "# assert os.path.isfile(os.path.join(NPZ_DIR, \"Point1_12_18_23_3X_interior_border_border\") + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"20190525_class_balance\"\n",
    "MODEL_DIR = os.path.join(\"/data/models\", experiment_folder)\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_name = \"Point1_12_18_3X_interior_border_border\"\n",
    "MODEL_NAME = npz_name + '_3_class_300k_max_class_examples_balanced_16_conv_filters'\n",
    "n_epoch = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 1024, 1024, 3) & y.shape: (3, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "training_data = np.load(os.path.join(NPZ_DIR, npz_name + \".npz\"))\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))\n",
    "\n",
    "# save the size of the input data for input_shape model parameter\n",
    "size = (RESHAPE_SIZE, RESHAPE_SIZE) if RESIZE else X.shape[ROW_AXIS:COL_AXIS + 1]\n",
    "if IS_CHANNELS_FIRST:\n",
    "    input_shape = (X.shape[CHANNEL_AXIS], size[0], size[1])\n",
    "else:\n",
    "    input_shape = (size[0], size[1], X.shape[CHANNEL_AXIS])\n",
    "\n",
    "# Set up other training parameters\n",
    "batch_size = 32\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = bn_feature_net_2D(\n",
    "    n_features=3,\n",
    "    n_dense_filters=128,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    receptive_field=61,\n",
    "    reg=1e-05,\n",
    "    norm_method=\"std\",\n",
    "    input_shape=input_shape,\n",
    "    n_conv_filters=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved model\n",
    "# model.load_weights('/data/models/Point1_12_18_3X_interior_callback_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point1_12_18_3X_interior_border_border_3_class_300k_max_class_examples_balanced_16_conv_filters\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0}\n",
      "X_train shape: (3, 1024, 1024, 3)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 3)\n",
      "Number of Classes: 3\n",
      "Training on 1 GPUs\n",
      "Dilation raidus is set to 1\n",
      "the max_class_samples per image is 100000\n",
      "analyzing image 0\n",
      "the least represented class has 122478 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 122478 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 265307 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 539584 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 93322 examples\n",
      "analyzing class 0\n",
      "downsampling from 93322 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 369638 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 464409 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 101744 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 101744 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 431054 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 394571 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/40\n",
      " 1144/27498 [>.............................] - ETA: 26:48 - loss: 0.5439 - acc: 0.7234"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = deepcell.training.train_model_sample(\n",
    "    max_class_samples=300000,\n",
    "    dataset=os.path.join(NPZ_DIR, npz_name + \".npz\"),\n",
    "    direc_data=NPZ_DIR,\n",
    "    batch_size=batch_size,\n",
    "    rotation_range=180,\n",
    "    balance_classes=True,\n",
    "    model=model,\n",
    "    n_epoch=n_epoch,\n",
    "    model_dir=MODEL_DIR,\n",
    "    transform=\"deepcell_old\",\n",
    "    log_dir=LOG_DIR,\n",
    "    dilation_radius=1,\n",
    "    shear=False,\n",
    "    lr_sched=lr_sched,\n",
    "    window_size=(30, 30),\n",
    "    flip=True,\n",
    "    optimizer=optimizer,\n",
    "    expt=\"sample_deepcell\",\n",
    "    model_name=MODEL_NAME,\n",
    "    val_monitor=False,\n",
    "    save_period=5,\n",
    "    class_weights=None\n",
    "    #class_weights={0:3, 1:1, 2:1}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
