{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A template Jupyter notebook to further train models.\n",
    "Data is given in compressed form and extracted for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.python import keras\n",
    "\n",
    "from deepcell.utils.data_utils import make_training_data\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.io_utils import get_image_sizes\n",
    "from deepcell.utils.export_utils import export_model\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.model_zoo import bn_feature_net_2D\n",
    "from deepcell.model_zoo import bn_feature_net_skip_2D\n",
    "from deepcell.training import train_model_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = False\n",
    "RESHAPE_SIZE = 256\n",
    "\n",
    "# filepath constants\n",
    "ROOT_DIR = \"/data/output\"\n",
    "DATA_DIR = \"/data/contour_data/\"\n",
    "MODEL_DIR = \"/data/models\"\n",
    "NPZ_DIR = \"/data/npz_data\"\n",
    "LOG_DIR = \"/data/logs\"\n",
    "DATA_FILE = \"Point1_12_18_3X\"\n",
    "RAW_PATH = os.path.join(DATA_DIR, DATA_FILE)\n",
    "\n",
    "# Check for channels_first or channels_last\n",
    "IS_CHANNELS_FIRST = keras.backend.image_data_format() == \"channels_first\"\n",
    "ROW_AXIS = 2 if IS_CHANNELS_FIRST else 1\n",
    "COL_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else 3\n",
    "\n",
    "N_FRAMES = 5\n",
    "\n",
    "# for d in (NPZ_DIR, MODEL_DIR, LOG_DIR, DATA_DIR):\n",
    "#     if not d.startswith(\"/\"):\n",
    "#         continue  # not a local directory, no need to create it\n",
    "#     try:\n",
    "#         os.makedirs(d)\n",
    "#     except OSError as exc:\n",
    "#         if exc.errno != errno.EEXIST:\n",
    "#             raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_training_data(\n",
    "#     channel_names=['Nuclear_Interior.tif'],\n",
    "#     file_name_save=os.path.join(NPZ_DIR, \"Point1_12_18_3X_interior\"),\n",
    "#     dimensionality=2,\n",
    "#     annotation_direc=\"annotated\",\n",
    "#     annotation_name='Nuclear_Interior_Mask_Label',\n",
    "#     reshape_size=RESHAPE_SIZE if RESIZE else None,\n",
    "#     training_direcs=None,\n",
    "#     raw_image_direc=\"raw\",\n",
    "#     direc_name=os.path.join(DATA_DIR, DATA_FILE)\n",
    "# )\n",
    "\n",
    "# assert os.path.isfile(os.path.join(NPZ_DIR, \"Point1_12_18_3X_interior\") + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"20190504_new_structure\"\n",
    "MODEL_DIR = os.path.join(MODEL_DIR, experiment_folder)\n",
    "os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_name = \"Point1_12_18_3X_interior\"\n",
    "MODEL_NAME = npz_name + '_hello_word'\n",
    "n_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 1024, 1024, 1) & y.shape: (3, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "training_data = np.load(os.path.join(NPZ_DIR, npz_name + \".npz\"))\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))\n",
    "\n",
    "# save the size of the input data for input_shape model parameter\n",
    "size = (RESHAPE_SIZE, RESHAPE_SIZE) if RESIZE else X.shape[ROW_AXIS:COL_AXIS + 1]\n",
    "if IS_CHANNELS_FIRST:\n",
    "    input_shape = (X.shape[CHANNEL_AXIS], size[0], size[1])\n",
    "else:\n",
    "    input_shape = (size[0], size[1], X.shape[CHANNEL_AXIS])\n",
    "\n",
    "# Set up other training parameters\n",
    "batch_size = 32\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = bn_feature_net_2D(\n",
    "    n_features=4,\n",
    "    n_dense_filters=128,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    receptive_field=61,\n",
    "    reg=1e-05,\n",
    "    norm_method=\"std\",\n",
    "    input_shape=input_shape,\n",
    "    n_conv_filters=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved model\n",
    "# model.load_weights('/data/models/Point1_12_18_3X_interior_callback_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "X_train shape: (3, 1024, 1024, 1)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "running model without validation checks\n",
      "Epoch 1/4\n",
      "9374/9374 [==============================] - 203s 22ms/step - loss: 0.3563 - acc: 0.7595\n",
      "Epoch 2/4\n",
      "4713/9374 [==============>...............] - ETA: 1:43 - loss: 0.3526 - acc: 0.7605"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = train_model_sample(\n",
    "    max_class_samples=100000,\n",
    "    dataset=os.path.join(NPZ_DIR, npz_name + \".npz\"),\n",
    "    direc_data=NPZ_DIR,\n",
    "    batch_size=batch_size,\n",
    "    rotation_range=180,\n",
    "    balance_classes=True,\n",
    "    model=model,\n",
    "    n_epoch=n_epoch,\n",
    "    model_dir=MODEL_DIR,\n",
    "    transform=\"deepcell\",\n",
    "    log_dir=LOG_DIR,\n",
    "    dilation_radius=1,\n",
    "    shear=False,\n",
    "    lr_sched=lr_sched,\n",
    "    window_size=(30, 30),\n",
    "    flip=True,\n",
    "    optimizer=optimizer,\n",
    "    expt=\"sample_deepcell\",\n",
    "    model_name=MODEL_NAME,\n",
    "    val_monitor=False,\n",
    "    save_period=2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
