{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "A template Jupyter notebook to further train models.\n",
    "Data is given in compressed form and extracted for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/deepcell/utils/__init__.py:49: UserWarning: To use `compute_overlap`, the C extensions must be built using `python setup.py build_ext --inplace`\n",
      "  warnings.warn('To use `compute_overlap`, the C extensions must be built '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.python import keras\n",
    "\n",
    "from deepcell.utils.data_utils import make_training_data\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.io_utils import get_image_sizes\n",
    "from deepcell.utils.export_utils import export_model\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.model_zoo import bn_feature_net_2D\n",
    "from deepcell.model_zoo import bn_feature_net_skip_2D\n",
    "#from deepcell.training import train_model_sample\n",
    "import deepcell.training\n",
    "import deepcell.image_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'deepcell.image_generators' from '/usr/local/lib/python3.5/dist-packages/deepcell/image_generators.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(deepcell.training)\n",
    "importlib.reload(deepcell.image_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = False\n",
    "RESHAPE_SIZE = 256\n",
    "\n",
    "# filepath constants\n",
    "ROOT_DIR = \"/data/output\"\n",
    "DATA_DIR = \"/data/contour_data/\"\n",
    "MODEL_DIR = \"/data/models\"\n",
    "NPZ_DIR = \"/data/npz_data\"\n",
    "LOG_DIR = \"/data/logs\"\n",
    "DATA_FILE = \"Point1_12_18_3X\"\n",
    "RAW_PATH = os.path.join(DATA_DIR, DATA_FILE)\n",
    "\n",
    "# Check for channels_first or channels_last\n",
    "IS_CHANNELS_FIRST = keras.backend.image_data_format() == \"channels_first\"\n",
    "ROW_AXIS = 2 if IS_CHANNELS_FIRST else 1\n",
    "COL_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else 3\n",
    "\n",
    "N_FRAMES = 5\n",
    "\n",
    "# for d in (NPZ_DIR, MODEL_DIR, LOG_DIR, DATA_DIR):\n",
    "#     if not d.startswith(\"/\"):\n",
    "#         continue  # not a local directory, no need to create it\n",
    "#     try:\n",
    "#         os.makedirs(d)\n",
    "#     except OSError as exc:\n",
    "#         if exc.errno != errno.EEXIST:\n",
    "#             raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_training_data(\n",
    "#     channel_names=['Nuclear_Interior.tif'],\n",
    "#     file_name_save=os.path.join(NPZ_DIR, \"Point1_12_18_3X_interior\"),\n",
    "#     dimensionality=2,\n",
    "#     annotation_direc=\"annotated\",\n",
    "#     annotation_name='Nuclear_Interior_Border_Mask_Label',\n",
    "#     reshape_size=RESHAPE_SIZE if RESIZE else None,\n",
    "#     training_direcs=None,\n",
    "#     raw_image_direc=\"raw\",\n",
    "#     direc_name=os.path.join(DATA_DIR, DATA_FILE)\n",
    "# )\n",
    "\n",
    "# assert os.path.isfile(os.path.join(NPZ_DIR, \"Point1_12_18_23_3X_interior_border_border\") + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for this set of experiments\n",
    "experiment_folder = \"20190620_debug\"\n",
    "MODEL_DIR = os.path.join(\"/data/models\", experiment_folder)\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_name = \"Point1_12_18_3X_interior\"\n",
    "MODEL_NAME = npz_name + '_validation_check'\n",
    "n_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 1024, 1024, 1) & y.shape: (3, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "training_data = np.load(os.path.join(NPZ_DIR, npz_name + \".npz\"))\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))\n",
    "\n",
    "# save the size of the input data for input_shape model parameter\n",
    "size = (RESHAPE_SIZE, RESHAPE_SIZE) if RESIZE else X.shape[ROW_AXIS:COL_AXIS + 1]\n",
    "if IS_CHANNELS_FIRST:\n",
    "    input_shape = (X.shape[CHANNEL_AXIS], size[0], size[1])\n",
    "else:\n",
    "    input_shape = (size[0], size[1], X.shape[CHANNEL_AXIS])\n",
    "\n",
    "# Set up other training parameters\n",
    "batch_size = 32\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = bn_feature_net_2D(\n",
    "    n_features=3,\n",
    "    n_dense_filters=128,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    receptive_field=61,\n",
    "    reg=1e-05,\n",
    "    norm_method=\"std\",\n",
    "    input_shape=input_shape,\n",
    "    n_conv_filters=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved model\n",
    "# model.load_weights('/data/models/Point1_12_18_3X_interior_callback_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point1_12_18_3X_interior_validation_check\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0}\n",
      "X_train shape: (2, 1024, 1024, 1)\n",
      "y_train shape: (2, 1024, 1024, 1)\n",
      "Output Shape: (None, 3)\n",
      "Number of Classes: 3\n",
      "Training on 1 GPUs\n",
      "Dilation raidus is set to 1\n",
      "the max_class_samples per image is 50000\n",
      "analyzing image 0\n",
      "the least represented class has 101744 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 101744 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 431054 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 394571 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 93322 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 93322 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 369638 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 464409 examples per class\n",
      "Dilation raidus is set to 1\n",
      "the max_class_samples per image is 100000\n",
      "analyzing image 0\n",
      "the least represented class has 122478 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "thresholding from 122478 to max_class_samples\n",
      "analyzing class 1\n",
      "thresholding from 265307 to max_class_samples\n",
      "analyzing class 2\n",
      "thresholding from 539584 to max_class_samples\n",
      "Epoch 1/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.7731\n",
      "Epoch 00001: val_loss improved from inf to 0.46970, saving model to /data/models/20190620_debug/Point1_12_18_3X_interior_validation_check.h5\n",
      "9375/9375 [==============================] - 356s 38ms/step - loss: 0.4575 - acc: 0.7731 - val_loss: 0.4697 - val_acc: 0.7808\n",
      "Epoch 2/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.7817\n",
      "Epoch 00002: val_loss did not improve from 0.46970\n",
      "9375/9375 [==============================] - 353s 38ms/step - loss: 0.4371 - acc: 0.7817 - val_loss: 0.4922 - val_acc: 0.7837\n",
      "Epoch 3/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.7847\n",
      "Epoch 00003: val_loss improved from 0.46970 to 0.46432, saving model to /data/models/20190620_debug/Point1_12_18_3X_interior_validation_check.h5\n",
      "9375/9375 [==============================] - 354s 38ms/step - loss: 0.4318 - acc: 0.7847 - val_loss: 0.4643 - val_acc: 0.7794\n",
      "Epoch 4/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4276 - acc: 0.7869\n",
      "Epoch 00004: val_loss improved from 0.46432 to 0.45681, saving model to /data/models/20190620_debug/Point1_12_18_3X_interior_validation_check.h5\n",
      "9375/9375 [==============================] - 351s 37ms/step - loss: 0.4276 - acc: 0.7869 - val_loss: 0.4568 - val_acc: 0.7883\n",
      "Epoch 5/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.7876\n",
      "Epoch 00005: val_loss improved from 0.45681 to 0.44196, saving model to /data/models/20190620_debug/Point1_12_18_3X_interior_validation_check.h5\n",
      "9375/9375 [==============================] - 352s 38ms/step - loss: 0.4255 - acc: 0.7876 - val_loss: 0.4420 - val_acc: 0.7996\n",
      "Epoch 6/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4243 - acc: 0.7875\n",
      "Epoch 00006: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.4243 - acc: 0.7875 - val_loss: 0.4800 - val_acc: 0.7722\n",
      "Epoch 7/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4218 - acc: 0.7888\n",
      "Epoch 00007: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.4218 - acc: 0.7888 - val_loss: 0.4623 - val_acc: 0.7876\n",
      "Epoch 8/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4208 - acc: 0.7894\n",
      "Epoch 00008: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 352s 38ms/step - loss: 0.4208 - acc: 0.7894 - val_loss: 0.4543 - val_acc: 0.7890\n",
      "Epoch 9/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4191 - acc: 0.7894\n",
      "Epoch 00009: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.4191 - acc: 0.7894 - val_loss: 0.4654 - val_acc: 0.7890\n",
      "Epoch 10/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4178 - acc: 0.7909\n",
      "Epoch 00010: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.4178 - acc: 0.7909 - val_loss: 0.4758 - val_acc: 0.7856\n",
      "Epoch 11/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4170 - acc: 0.7916\n",
      "Epoch 00011: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.4170 - acc: 0.7916 - val_loss: 0.4723 - val_acc: 0.7806\n",
      "Epoch 12/30\n",
      "6773/9375 [====================>.........] - ETA: 1:14 - loss: 0.4144 - acc: 0.7940\n",
      "Epoch 00012: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 355s 38ms/step - loss: 0.4155 - acc: 0.7933 - val_loss: 0.4883 - val_acc: 0.7761\n",
      "Epoch 13/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4118 - acc: 0.7948\n",
      "Epoch 00015: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 368s 39ms/step - loss: 0.4118 - acc: 0.7947 - val_loss: 0.4874 - val_acc: 0.7710\n",
      "Epoch 16/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.7952\n",
      "Epoch 00016: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 347s 37ms/step - loss: 0.4102 - acc: 0.7952 - val_loss: 0.4950 - val_acc: 0.7730\n",
      "Epoch 17/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.7965\n",
      "Epoch 00017: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 349s 37ms/step - loss: 0.4089 - acc: 0.7965 - val_loss: 0.4698 - val_acc: 0.7836\n",
      "Epoch 18/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4084 - acc: 0.7958\n",
      "Epoch 00018: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 348s 37ms/step - loss: 0.4084 - acc: 0.7958 - val_loss: 0.4621 - val_acc: 0.7856\n",
      "Epoch 19/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.7979\n",
      "Epoch 00019: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.4063 - acc: 0.7979 - val_loss: 0.5105 - val_acc: 0.7637\n",
      "Epoch 20/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.7983\n",
      "Epoch 00020: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 347s 37ms/step - loss: 0.4054 - acc: 0.7983 - val_loss: 0.4701 - val_acc: 0.7810\n",
      "Epoch 21/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8022\n",
      "Epoch 00021: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 348s 37ms/step - loss: 0.4003 - acc: 0.8022 - val_loss: 0.4611 - val_acc: 0.7864\n",
      "Epoch 22/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8047\n",
      "Epoch 00022: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 351s 37ms/step - loss: 0.3973 - acc: 0.8046 - val_loss: 0.4674 - val_acc: 0.7816\n",
      "Epoch 23/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.3906 - acc: 0.8087\n",
      "Epoch 00023: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 377s 40ms/step - loss: 0.3906 - acc: 0.8087 - val_loss: 0.4913 - val_acc: 0.7695\n",
      "Epoch 24/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.3825 - acc: 0.8138\n",
      "Epoch 00024: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 351s 37ms/step - loss: 0.3825 - acc: 0.8138 - val_loss: 0.4749 - val_acc: 0.7748\n",
      "Epoch 25/30\n",
      "9374/9375 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8212\n",
      "Epoch 00025: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 351s 37ms/step - loss: 0.3703 - acc: 0.8212 - val_loss: 0.4864 - val_acc: 0.7716\n",
      "Epoch 26/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.3593 - acc: 0.8274\n",
      "Epoch 00026: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 351s 37ms/step - loss: 0.3593 - acc: 0.8274 - val_loss: 0.4832 - val_acc: 0.7689\n",
      "Epoch 27/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.3505 - acc: 0.8319\n",
      "Epoch 00027: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 351s 37ms/step - loss: 0.3505 - acc: 0.8319 - val_loss: 0.4611 - val_acc: 0.7862\n",
      "Epoch 28/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8367\n",
      "Epoch 00028: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 352s 38ms/step - loss: 0.3441 - acc: 0.8367 - val_loss: 0.4877 - val_acc: 0.7714\n",
      "Epoch 29/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.3395 - acc: 0.8394\n",
      "Epoch 00029: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.3396 - acc: 0.8394 - val_loss: 0.4966 - val_acc: 0.7697\n",
      "Epoch 30/30\n",
      "9373/9375 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8423\n",
      "Epoch 00030: val_loss did not improve from 0.44196\n",
      "9375/9375 [==============================] - 350s 37ms/step - loss: 0.3350 - acc: 0.8423 - val_loss: 0.4953 - val_acc: 0.7678\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = deepcell.training.train_model_sample(\n",
    "    max_class_samples=100000,\n",
    "    dataset=os.path.join(NPZ_DIR, npz_name + \".npz\"),\n",
    "    direc_data=NPZ_DIR,\n",
    "    batch_size=batch_size,\n",
    "    rotation_range=180,\n",
    "    balance_classes=True,\n",
    "    model=model,\n",
    "    n_epoch=n_epoch,\n",
    "    model_dir=MODEL_DIR,\n",
    "    transform=\"deepcell_old\",\n",
    "    log_dir=LOG_DIR,\n",
    "    dilation_radius=1,\n",
    "    shear=False,\n",
    "    lr_sched=lr_sched,\n",
    "    window_size=(30, 30),\n",
    "    flip=True,\n",
    "    optimizer=optimizer,\n",
    "    expt=\"sample_deepcell\",\n",
    "    model_name=MODEL_NAME,\n",
    "    val_monitor=True,\n",
    "    save_period=5,\n",
    "    class_weights=None\n",
    "    #class_weights={0:3, 1:1, 2:1}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
