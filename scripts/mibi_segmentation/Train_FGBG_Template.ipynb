{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import numpy as np\n",
    "import deepcell\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "test_size = .10  # % of data saved as test\n",
    "receptive_field = 81  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "balance_classes = True  # sample each class equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Training_Freeze_1'\n",
    "npz_name = '/data/npz_data/' + base_name + \".npz\"\n",
    "MODEL_DIR = '/data/models/' + '20190822_training_freeze_1'\n",
    "fgbg_model_name = base_name + \"_fgbg_81_rf_256_dense_64_conv_subsampled\"\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "LOG_DIR = '/data/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (4, 1024, 1024, 5) & y.shape: (4, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "CHANNEL_AXIS = 3\n",
    "training_data = np.load(npz_name)\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "fgbg_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training_Freeze_1_fgbg_81_rf_256_dense_64_conv_subsampled'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgbg_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0}\n",
      "X_train shape: (4, 1024, 1024, 5)\n",
      "y_train shape: (4, 1024, 1024, 1)\n",
      "Output Shape: (None, 2)\n",
      "Number of Classes: 2\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 100000\n",
      "analyzing image 0\n",
      "the least represented class has 91377 examples\n",
      "analyzing class 0\n",
      "downsampling from 91377 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 797872 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 299309 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 299309 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 589940 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 267420 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 267420 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 621829 examples per class\n",
      "analyzing image 3\n",
      "the least represented class has 36648 examples\n",
      "analyzing class 0\n",
      "downsampling from 36648 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 852601 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/24\n",
      " 103/5125 [..............................] - ETA: 56:34 - loss: 0.4469 - acc: 0.7926"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_sample\n",
    "\n",
    "fgbg_model = train_model_sample(\n",
    "    model=fgbg_model,\n",
    "    dataset=npz_name,\n",
    "    model_name=fgbg_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    window_size=(win, win),\n",
    "    batch_size=128,\n",
    "    transform='fgbg',\n",
    "    n_epoch=24,\n",
    "    balance_classes=balance_classes,\n",
    "    max_class_samples=400000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
