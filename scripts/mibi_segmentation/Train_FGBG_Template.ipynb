{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/deepcell/utils/__init__.py:49: UserWarning: To use `compute_overlap`, the C extensions must be built using `python setup.py build_ext --inplace`\n",
      "  warnings.warn('To use `compute_overlap`, the C extensions must be built '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell\n",
    "from tensorflow.python import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "n_epoch = 21  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "balance_classes = True  # sample each class equally\n",
    "max_class_samples = 1e6  # max number of samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'First_Try'\n",
    "npz_name = '/data/npz_data/' + base_name + \".npz\"\n",
    "MODEL_DIR = '/data/models/' + '20190816_first_try'\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "LOG_DIR = '/data/logs'\n",
    "\n",
    "\n",
    "fgbg_model_name = base_name + \"_fgbg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 1024, 1024, 5) & y.shape: (3, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "CHANNEL_AXIS = 3\n",
    "training_data = np.load(npz_name)\n",
    "\n",
    "X, y = training_data[\"X\"], training_data[\"y\"]\n",
    "print(\"X.shape: {} & y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "fgbg_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0}\n",
      "X_train shape: (3, 1024, 1024, 5)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 2)\n",
      "Number of Classes: 2\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 333333\n",
      "analyzing image 0\n",
      "the least represented class has 97419 examples\n",
      "analyzing class 0\n",
      "downsampling from 97419 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 829950 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 316539 examples\n",
      "analyzing class 0\n",
      "downsampling from 316539 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 610830 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 41153 examples\n",
      "analyzing class 0\n",
      "downsampling from 41153 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 886216 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/5\n",
      "1290/7111 [====>.........................] - ETA: 23:30 - loss: 0.3308 - acc: 0.8567"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_sample\n",
    "\n",
    "fgbg_model = train_model_sample(\n",
    "    model=fgbg_model,\n",
    "    dataset=npz_name,\n",
    "    model_name=fgbg_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    window_size=(win, win),\n",
    "    batch_size=128,\n",
    "    transform='fgbg',\n",
    "    n_epoch=5,\n",
    "    balance_classes=balance_classes,\n",
    "    max_class_samples=1000000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, Create a model for the watershed energy transform\n",
    "\n",
    "#### Instantiate the distance transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "from deepcell.training import train_model_sample\n",
    "\n",
    "watershed_model = model_zoo.bn_feature_net_2D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_channels=X.shape[CHANNEL_AXIS],\n",
    "    n_features=distance_bins,\n",
    "    n_conv_filters=64,\n",
    "    n_dense_filters=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First_Try_watershed_256_dense_64_conv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_name\n",
    "#watershed_model.load_weights('/data/models/20190606_params/Point1_12_18_3X_interior_border_border_watershed_128_filters_balanced_epoch_40.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using all data as training data\n",
      "Using class weights of {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "X_train shape: (3, 1024, 1024, 5)\n",
      "y_train shape: (3, 1024, 1024, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n",
      "the max_class_samples per image is 60000\n",
      "analyzing image 0\n",
      "the least represented class has 70512 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 455411 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 241755 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 159691 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 70512 examples per class\n",
      "analyzing image 1\n",
      "the least represented class has 52702 examples\n",
      "analyzing class 0\n",
      "downsampling from 577293 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 178981 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 118393 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 52702 examples per class\n",
      "analyzing image 2\n",
      "the least represented class has 74422 examples\n",
      "max_class_samples is less than the smalleset class, downsampling all classes\n",
      "analyzing class 0\n",
      "downsampling from 426807 examples per class\n",
      "analyzing class 1\n",
      "downsampling from 258000 examples per class\n",
      "analyzing class 2\n",
      "downsampling from 168140 examples per class\n",
      "analyzing class 3\n",
      "downsampling from 74422 examples per class\n",
      "running model without validation checks\n",
      "Epoch 1/21\n",
      "   55/10793 [..............................] - ETA: 32:27 - loss: 1.0964 - acc: 0.4625"
     ]
    }
   ],
   "source": [
    "watershed_model = train_model_sample(\n",
    "    model=watershed_model,\n",
    "    dataset=npz_name, \n",
    "    model_name=sample_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=21,\n",
    "    window_size=(win, win),\n",
    "    transform=transform,\n",
    "    distance_bins=distance_bins,\n",
    "    erosion_width=erosion_width,\n",
    "    balance_classes=True,\n",
    "    max_class_samples=180000,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    val_monitor=False,\n",
    "    save_period=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
